{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP6 : Segmentation d'images\n",
    "\n",
    "L'objectif de ce TPs est de mettre en application les différentes approches de segmentation vues dans le cours et notamment :\n",
    " + Les approches basées sur le clustering\n",
    " + L'approche super-pixels\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Segmentation par clustering (d'après CS 131)\n",
    "\n",
    "Dans cette partie, il s'agit d'utiliser des algorithmes de clustering pour la segmentation d'images. Elle consiste en trois exercices dépendants :\n",
    "\n",
    " 1. Exercice 1 : implémentation de deux algorithmes classiques de clustering : k-means et clustering hiérarchique (HAC)\n",
    " 2. Exercice 2 : construction d'un vecteur de caractéristiques au niveau des pixels prenant en compte la couleur et la position.\n",
    " 3. Exercice 3 : évaluation quantitative de l'approche de segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1 : Algorithmes de clustering\n",
    "\n",
    "Appliquer le code ci-dessous qui permet de générer un ensemble de 4 clusters de points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "# Generate random data points for clustering\n",
    "\n",
    "# Set seed for consistency\n",
    "np.random.seed(0)\n",
    "\n",
    "# Cluster 1\n",
    "mean1 = [-1, 0]\n",
    "cov1 = [[0.1, 0], [0, 0.1]]\n",
    "X1 = np.random.multivariate_normal(mean1, cov1, 100)\n",
    "\n",
    "# Cluster 2\n",
    "mean2 = [0, 1]\n",
    "cov2 = [[0.1, 0], [0, 0.1]]\n",
    "X2 = np.random.multivariate_normal(mean2, cov2, 100)\n",
    "\n",
    "# Cluster 3\n",
    "mean3 = [1, 0]\n",
    "cov3 = [[0.1, 0], [0, 0.1]]\n",
    "X3 = np.random.multivariate_normal(mean3, cov3, 100)\n",
    "\n",
    "# Cluster 4\n",
    "mean4 = [0, -1]\n",
    "cov4 = [[0.1, 0], [0, 0.1]]\n",
    "X4 = np.random.multivariate_normal(mean4, cov4, 100)\n",
    "\n",
    "# Merge two sets of data points\n",
    "X = np.concatenate((X1, X2, X3, X4))\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithme k-means\n",
    "\n",
    "Compléter le code ci-dessous pour avoir une implémentation de l'algorithme k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "### Clustering Methods\n",
    "def kmeans(features, k, num_iters=100):\n",
    "    \"\"\" Use kmeans algorithm to group features into k clusters.\n",
    "    K-Means algorithm can be broken down into following steps:\n",
    "        1. Randomly initialize cluster centers\n",
    "        2. Assign each point to the closest center\n",
    "        3. Compute new center of each cluster\n",
    "        4. Stop if cluster assignments did not change\n",
    "        5. Go to step 2\n",
    "    Args:\n",
    "        features - Array of N features vectors. Each row represents a feature\n",
    "            vector.\n",
    "        k - Number of clusters to form.\n",
    "        num_iters - Maximum number of iterations the algorithm will run.\n",
    "    Returns:\n",
    "        assignments - Array representing cluster assignment of each point.\n",
    "            (e.g. i-th point is assigned to cluster assignments[i])\n",
    "    \"\"\"\n",
    "\n",
    "    N, D = features.shape\n",
    "\n",
    "    assert N >= k, 'Number of clusters cannot be greater than number of points'\n",
    "\n",
    "    # Randomly initalize cluster centers\n",
    "    idxs = np.random.choice(N, size=k, replace=False)\n",
    "    centers = features[idxs]\n",
    "    assignments = np.zeros(N, dtype=np.uint32)\n",
    "\n",
    "    for n in range(num_iters):\n",
    "        ### To complete\n",
    "        pass\n",
    "        ### To complete\n",
    "\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester votre algorithme sur le jeu de données synthétique et mesurer son temps d'exécution en exécutant le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "np.random.seed(0)\n",
    "start = time()\n",
    "assignments = kmeans(X, 4)\n",
    "end = time()\n",
    "\n",
    "kmeans_runtime = end - start\n",
    "\n",
    "print(\"kmeans running time: %f seconds.\" % kmeans_runtime)\n",
    "\n",
    "for i in range(4):\n",
    "    cluster_i = X[assignments==i]\n",
    "    plt.scatter(cluster_i[:, 0], cluster_i[:, 1])\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide des fonctions de la bibliothèque numpy, essayez de rendre le calcul plus rapide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_fast(features, k, num_iters=100):\n",
    "    \"\"\" Use kmeans algorithm to group features into k clusters.\n",
    "    This function makes use of numpy functions and broadcasting to speed up the\n",
    "    first part(cluster assignment) of kmeans algorithm.\n",
    "    Hints\n",
    "    - You may find np.repeat and np.argmin useful\n",
    "    Args:\n",
    "        features - Array of N features vectors. Each row represents a feature\n",
    "            vector.\n",
    "        k - Number of clusters to form.\n",
    "        num_iters - Maximum number of iterations the algorithm will run.\n",
    "    Returns:\n",
    "        assignments - Array representing cluster assignment of each point.\n",
    "            (e.g. i-th point is assigned to cluster assignments[i])\n",
    "    \"\"\"\n",
    "\n",
    "    N, D = features.shape\n",
    "\n",
    "    assert N >= k, 'Number of clusters cannot be greater than number of points'\n",
    "\n",
    "    # Randomly initalize cluster centers\n",
    "    idxs = np.random.choice(N, size=k, replace=False)\n",
    "    centers = features[idxs]\n",
    "    assignments = np.zeros(N, dtype=np.uint32)\n",
    "\n",
    "    for n in range(num_iters):\n",
    "        ### YOUR CODE HERE\n",
    "        pass\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    return assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester votre fonction sur le jeu de données synthétiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "start = time()\n",
    "assignments = kmeans_fast(X, 4)\n",
    "end = time()\n",
    "\n",
    "kmeans_fast_runtime = end - start\n",
    "print(\"kmeans running time: %f seconds.\" % kmeans_fast_runtime)\n",
    "print(\"%f times faster!\" % (kmeans_runtime / kmeans_fast_runtime))\n",
    "\n",
    "for i in range(4):\n",
    "    cluster_i = X[assignments==i]\n",
    "    plt.scatter(cluster_i[:, 0], cluster_i[:, 1])\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering hiérarchique\n",
    "\n",
    "Compléter le code ci-dessous pour avoir une implémentation de l'algorithme de clustering hiérarchique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hierarchical_clustering(features, k):\n",
    "    \"\"\" Run the hierarchical agglomerative clustering algorithm.\n",
    "    The algorithm is conceptually simple:\n",
    "    Assign each point to its own cluster\n",
    "    While the number of clusters is greater than k:\n",
    "        Compute the distance between all pairs of clusters\n",
    "        Merge the pair of clusters that are closest to each other\n",
    "    We will use Euclidean distance to define distance between clusters.\n",
    "    Recomputing the centroids of all clusters and the distances between all\n",
    "    pairs of centroids at each step of the loop would be very slow. Thankfully\n",
    "    most of the distances and centroids remain the same in successive\n",
    "    iterations of the outer loop; therefore we can speed up the computation by\n",
    "    only recomputing the centroid and distances for the new merged cluster.\n",
    "    Even with this trick, this algorithm will consume a lot of memory and run\n",
    "    very slowly when clustering large set of points. In practice, you probably\n",
    "    do not want to use this algorithm to cluster more than 10,000 points.\n",
    "    Args:\n",
    "        features - Array of N features vectors. Each row represents a feature\n",
    "            vector.\n",
    "        k - Number of clusters to form.\n",
    "    Returns:\n",
    "        assignments - Array representing cluster assignment of each point.\n",
    "            (e.g. i-th point is assigned to cluster assignments[i])\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    N, D = features.shape\n",
    "\n",
    "    assert N >= k, 'Number of clusters cannot be greater than number of points'\n",
    "\n",
    "    # Assign each point to its own cluster\n",
    "    assignments = np.arange(N, dtype=np.uint32)\n",
    "    centers = np.copy(features)\n",
    "    n_clusters = N\n",
    "\n",
    "    while n_clusters > k:\n",
    "        ### YOUR CODE HERE\n",
    "        pass\n",
    "        ### END YOUR CODE\n",
    "\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester le sur le jeu de données synthétiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "assignments = hierarchical_clustering(X, 4)\n",
    "end = time()\n",
    "\n",
    "print(\"hierarchical_clustering running time: %f seconds.\" % (end - start))\n",
    "\n",
    "for i in range(4):\n",
    "    cluster_i = X[assignments==i]\n",
    "    plt.scatter(cluster_i[:, 0], cluster_i[:, 1])\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2  : Application à la segmentation d'images\n",
    "\n",
    "Avant de pouvoir utiliser un algorithme de clustering pour segmenter une image, nous devons calculer un vecteur de caractéristiques pour chaque pixel. Le vecteur de caractéristiques pour chaque pixel doit coder les propriétés estimées utiles pour une bonne segmentation. Plus concrètement, pour une paire de pixels $p_i$ et $p_j$ avec les vecteurs caractéristiques correspondants $f_i$ et $f_j$, la distance entre $f_i$ et $f_j$ doit être petite si nous pensons que $p_i$ et $p_j$ doivent être placés dans le même cluster (region ici) et grande sinon.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charger et afficher une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "def loadImagebis(src):\n",
    "    img=cv2.imread(src,1)\n",
    "    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(rgb,interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "img=loadImagebis('./Images/oscar.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caractéristiques de couleur\n",
    "\n",
    "Une manière assez simple de caractériser un pixel est d'utiliser la valeur de la couleur en chaque pixel. Compléter la fonction ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_features(img):\n",
    "    \"\"\" Represents a pixel by its color.\n",
    "    Args:\n",
    "        img - array of shape (H, W, C)\n",
    "    Returns:\n",
    "        features - array of (H * W, C)\n",
    "    \"\"\"\n",
    "    H, W, C = img.shape\n",
    "    img = np.float32(img)\n",
    "    features = np.zeros((H*W, C))\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester sur votre image le clustering k-means rapide et eventuellement les autres approches de clustering en ne considérant que ce vecteur de caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "features = color_features(img)\n",
    "\n",
    "# Sanity checks\n",
    "assert features.shape == (H * W, C),\\\n",
    "    \"Incorrect shape! Check your implementation.\"\n",
    "\n",
    "assert features.dtype == np.float,\\\n",
    "    \"dtype of color_features should be float.\"\n",
    "\n",
    "assignments = kmeans_fast(features, 8)\n",
    "segments = assignments.reshape((H, W))\n",
    "\n",
    "# Display segmentation\n",
    "plt.imshow(segments, cmap='viridis')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction ci-dessous permet de visualiser chaque région comme la moyenne des pixels de la région."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mean_color_image(img, segments):\n",
    "\n",
    "    img = np.float32(img)\n",
    "    k = np.max(segments) + 1\n",
    "    mean_color_img = np.zeros(img.shape)\n",
    "\n",
    "    for i in range(k):\n",
    "        mean_color = np.mean(img[segments == i], axis=0)\n",
    "        mean_color_img[segments == i] = mean_color\n",
    "\n",
    "    plt.imshow(mean_color_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer la à votre image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caractéristiques de couleur et de position\n",
    "\n",
    "Un autre vecteur de caractéristique simple pour un pixel est de concaténer sa couleur et sa position dans l'image. En d'autres termes, pour un pixel de couleur $(r, g, b)$ situé à la position $(x, y)$ dans l'image, son vecteur de caractéristique serait $(r, g, b, x, y)$. Cependant, les caractéristiques de couleur et de position peuvent avoir des plages radicalement différentes ; par exemple, chaque canal de couleur d'une image peut se situer dans la plage $[0, 1)$, tandis que la position de chaque pixel peut avoir une plage beaucoup plus large. Une mauvaise mise à l'échelle entre les différentes caractéristiques du vecteur de caractéristiques peut entraîner un mauvais comportement des algorithmes de clustering.\n",
    "\n",
    "Une façon de corriger cela est d'appliquer une normalisation au vecteur de caractéristiques. L'un des types de normalisation les plus simples consiste à forcer chaque caractéristique à avoir une moyenne et une variance unitaire nulles.\n",
    "\n",
    "Compléter le code ci-dessous pour construire un tel vecteur de caractéristiques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_position_features(img):\n",
    "    \"\"\" Represents a pixel by its color and position.\n",
    "    Combine pixel's RGB value and xy coordinates into a feature vector.\n",
    "    i.e. for a pixel of color (r, g, b) located at position (x, y) in the\n",
    "    image. its feature vector would be (r, g, b, x, y).\n",
    "    Don't forget to normalize features.\n",
    "    Hints\n",
    "    - You may find np.mgrid and np.dstack useful\n",
    "    - You may use np.mean and np.std\n",
    "    Args:\n",
    "        img - array of shape (H, W, C)\n",
    "    Returns:\n",
    "        features - array of (H * W, C+2)\n",
    "    \"\"\"\n",
    "    H, W, C = img.shape\n",
    "    color = np.float32(img)\n",
    "    features = np.zeros((H*W, C+2))\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester sur votre image le clustering k-means rapide et eventuellement les autres approches de clustering en considérant ce nouveau vecteur de caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "features = color_position_features(img)\n",
    "\n",
    "# Sanity checks\n",
    "assert features.shape == (H * W, C + 2),\\\n",
    "    \"Incorrect shape! Check your implementation.\"\n",
    "\n",
    "assert features.dtype == np.float,\\\n",
    "    \"dtype of color_features should be float.\"\n",
    "\n",
    "assignments = kmeans_fast(features, 8)\n",
    "segments = assignments.reshape((H, W))\n",
    "\n",
    "# Display segmentation\n",
    "plt.imshow(segments, cmap='viridis')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualiser votre clustering à l'aide de la fonction `visualize_mean_color_image``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essayer d'améliorer le résultat du clustering en ajoutant et en calculant les caractéristiques qui vous semblent pertinentes pour la segmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_features(img):\n",
    "    \"\"\" Implement your own features\n",
    "    Args:\n",
    "        img - array of shape (H, W, C)\n",
    "    Returns:\n",
    "        features - array of (H * W, C)\n",
    "    \"\"\"\n",
    "    features = None\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "    ### END YOUR CODE\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 3  : Evaluation quantitative\n",
    "\n",
    "Il s'agit ici, sur un petit ensemble de données d'images de chats et des segmentations de ces images en avant-plan (chats) et en arrière-plan (tout le reste) d'évaluer les algorithmes de segmentation. \n",
    "\n",
    "Nous pouvons transposer la tâche de segmentation en un problème de classification binaire, où nous devons classer chaque pixel d'une image en avant-plan (positif) ou en arrière-plan (négatif). Compte tenu de la vérité terrain, la précision d'une segmentation est de $(TP+TN)/(P+N)$.\n",
    "Compléter la fonction ci-dessous permettant de calculer la précision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(mask_gt, mask):\n",
    "    \"\"\" Compute the pixel-wise accuracy of a foreground-background segmentation\n",
    "        given a ground truth segmentation.\n",
    "    Args:\n",
    "        mask_gt - The ground truth foreground-background segmentation. A\n",
    "            logical of size H x W where mask_gt[y, x] is 1 if and only if\n",
    "            pixel (y, x) of the original image was part of the foreground.\n",
    "        mask - The estimated foreground-background segmentation. A logical\n",
    "            array of the same size and format as mask_gt.\n",
    "    Returns:\n",
    "        accuracy - The fraction of pixels where mask_gt and mask agree. A\n",
    "            bigger number is better, where 1.0 indicates a perfect segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    accuracy = None\n",
    "    ### YOUR CODE HERE\n",
    "    pass\n",
    "    ### END YOUR CODE\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tester votre fonction avec le code ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_gt = np.zeros((100, 100))\n",
    "mask = np.zeros((100, 100))\n",
    "\n",
    "# Test compute_accracy function\n",
    "mask_gt[20:50, 30:60] = 1\n",
    "mask[30:50, 30:60] = 1\n",
    "\n",
    "accuracy = compute_accuracy(mask_gt, mask)\n",
    "\n",
    "print('Accuracy: %0.2f' % (accuracy))\n",
    "if accuracy != 0.97:\n",
    "    print('Check your implementation!')\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(mask_gt)\n",
    "plt.title('Ground Truth')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask)\n",
    "plt.title('Estimate')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessous vous permet de tester la fonction de votre choix sur le jeu de données fourni dans le répertoire [Data](./Data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def evaluate_segmentation(mask_gt, segments):\n",
    "    \"\"\" Compare the estimated segmentation with the ground truth.\n",
    "    Note that 'mask_gt' is a binary mask, while 'segments' contain k segments.\n",
    "    This function compares each segment in 'segments' with the ground truth and\n",
    "    outputs the accuracy of the best segment.\n",
    "    Args:\n",
    "        mask_gt - The ground truth foreground-background segmentation. A\n",
    "            logical of size H x W where mask_gt[y, x] is 1 if and only if\n",
    "            pixel (y, x) of the original image was part of the foreground.\n",
    "        segments - An array of the same size as mask_gt. The value of a pixel\n",
    "            indicates the segment it belongs.\n",
    "    Returns:\n",
    "        best_accuracy - Accuracy of the best performing segment.\n",
    "            0 <= accuracy <= 1, where 1.0 indicates a perfect segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    num_segments = np.max(segments) + 1\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Compare each segment in 'segments' with the ground truth\n",
    "    for i in range(num_segments):\n",
    "        mask = (segments == i).astype(int)\n",
    "        accuracy = compute_accuracy(mask_gt, mask)\n",
    "        best_accuracy = max(accuracy, best_accuracy)\n",
    "\n",
    "    return best_accuracy\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    This function assumes 'gt' directory contains ground truth segmentation\n",
    "    masks for images in 'imgs' dir. The segmentation mask for image\n",
    "    'imgs/aaa.jpg' is 'gt/aaa.png'\n",
    "    \"\"\"\n",
    "\n",
    "    imgs = []\n",
    "    gt_masks = []\n",
    "\n",
    "    # Load all the images under 'data_dir/imgs' and corresponding\n",
    "    # segmentation masks under 'data_dir/gt'.\n",
    "    for fname in sorted(os.listdir(os.path.join(data_dir, 'imgs'))):\n",
    "        if fname.endswith('.jpg'):\n",
    "            # Load image\n",
    "            img = cv2.imread(os.path.join(data_dir, 'imgs', fname))\n",
    "            imgs.append(img)\n",
    "\n",
    "            # Load corresponding gt segmentation mask\n",
    "            mask_fname = fname[:-4] + '.png'\n",
    "            gt_mask = cv2.imread(os.path.join(data_dir, 'gt', mask_fname))\n",
    "            gt_mask = (gt_mask != 0).astype(int) # Convert to binary mask (0s and 1s)\n",
    "            gt_masks.append(gt_mask)\n",
    "\n",
    "    return imgs, gt_masks\n",
    "\n",
    "\n",
    "\n",
    "# Load a small segmentation dataset\n",
    "imgs, gt_masks = load_dataset('./data')\n",
    "\n",
    "# Set the parameters for segmentation.\n",
    "num_segments = 3\n",
    "clustering_fn = kmeans_fast\n",
    "feature_fn = color_features\n",
    "scale = 0.5\n",
    "\n",
    "mean_accuracy = 0.0\n",
    "\n",
    "segmentations = []\n",
    "\n",
    "for i, (img, gt_mask) in enumerate(zip(imgs, gt_masks)):\n",
    "    # Compute a segmentation for this image\n",
    "    segments = compute_segmentation(img, num_segments,\n",
    "                                    clustering_fn=clustering_fn,\n",
    "                                    feature_fn=feature_fn,\n",
    "                                    scale=scale)\n",
    "    \n",
    "    segmentations.append(segments)\n",
    "    \n",
    "    # Evaluate segmentation\n",
    "    accuracy = evaluate_segmentation(gt_mask, segments)\n",
    "    \n",
    "    print('Accuracy for image %d: %0.4f' %(i, accuracy))\n",
    "    mean_accuracy += accuracy\n",
    "    \n",
    "mean_accuracy = mean_accuracy / len(imgs)\n",
    "print('Mean accuracy: %0.4f' % mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Approche super-pixels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie il s'agit de mettre en place l'approche de segmentation par super-pixels décrite dans le cours et avec plus de détails [ici](https://www.iro.umontreal.ca/~mignotte/IFT6150/Articles/SLIC_Superpixels.pdf).\n",
    "\n",
    "Le principe de l'algorithme SLIC (Simple Linear Iterative Clustering) est le suivant :\n",
    " + les pixels sont groupés en superpixels rectangulaires et réguliers\n",
    " + chaque superpixel est décrit par sa couleur moyenne et la localisation de son barycentre\n",
    " + chaque pixel est ré-attribué au superpixel dont il est le plus proche en terme de couleur et de localisation\n",
    " + les étapes 2 et 3 sont répétées jusqu'à ce que les superpixels soient stables\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 1 : SLIC\n",
    "\n",
    "Ecrire une fonction qui prend en entrée une image, un espace colorimétrique, un nombre de segments et qui applique l'algorithme SLIC. \n",
    "Pour cela vous pouvez par exemple vous inspirer ou utiliser l'implémentation qui a été faite dans la bibliothèque scikit-image [ici](https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.slic) dont le code source est disponible [ici](https://github.com/scikit-image/scikit-image/blob/master/skimage/segmentation/slic_superpixels.py#L11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tester sur plusieurs images en jouant sur les différents paramètres possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice 2 : Segmentation par apprentissage.\n",
    "\n",
    "Comme décrit dans le cours, nous allons maintenant utiliser les super-pixels et leur caractérisation pour modéliser la segmentation comme un problème d'apprentissage.\n",
    "Il s'agira donc :\n",
    " + D'associer à chaque superpixel un vecteur caractéristique.\n",
    " + Constituer un ensemble d'apprentissage sur un petit nombre d'images de votre choix et un petit nombre de classes \n",
    " + D'apprendre un modèle par exemple avec un SVM et de l'appliquer sur une nouvelle image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caractérisation des super-pixels\n",
    "\n",
    "Décrire chaque superpixel par cinq valeurs numériques : trois pour sa couleur moyenne et deux pour la position de son barycentre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base d'apprentissage\n",
    "\n",
    "Il s'agit ici de constituer un petit ensemble d'apprentissage composé de quelques images de scènes de même type. Choisissez 3 à 4 classes que vous aimeriez segmenter dans l'image. Par exemple, dans des images de paysages de plages, les classes pourraient être `mer`, `sable`, `ciel` et `autre`. Il s'agira donc dans un premier temps de mettre en place un programme permettant à un utilisateur d'annoter les images de votre base avec ces 4 classes. Pour cela vous pourrez utiliser les fonctions de dessins d'opencv décrites [ici](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_drawing_functions/py_drawing_functions.html) pour dessiner des traits de couleurs différentes pour chacune des classes sur les images de votre base d'apprentissage. Vous pouvez ici aussi vous inspirer de [cette approche](https://github.com/opencv/opencv/blob/master/samples/python/grabcut.py) pour la partie annotation.\n",
    "\n",
    "Ensuite, vous pouvez constituer une base d'apprentissage $(X,Y)$ en prenant pour chaque classe annotée, les superpixels correspondants (ceux qui correspondent au trait de couleur marqué pour la classe) et en prenant leur caractérisation.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE  : Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE : constituion de la base d'aprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apprentissage\n",
    "\n",
    "Apprendre un classifeur de superpixel à l'aide d'un SVM avec un noyau RBF. La documentation est [ici](https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_ml/py_svm/py_svm_basics/py_svm_basics.html#svm-understanding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquer le sur une nouvelle image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO COMPLETE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
